#!/usr/bin/env python3
"""
Dry Run Test - Framework'Ã¼n tam workflow'unu test eder
"""

import asyncio
import sys
from pathlib import Path
import structlog

# Setup
sys.path.insert(0, str(Path(__file__).parent))

from src.agents.crew_manager import CrewManager
from src.utils.yaml_loader import load_scenario, create_example_scenario

async def test_full_workflow():
    """Framework'Ã¼n tam workflow'unu test eder"""
    
    print("ğŸš€ Dry Run Test - Framework Workflow Testi")
    print("=" * 60)
    
    try:
        # 1. Test scenario oluÅŸtur
        print("\nğŸ“ Test scenario oluÅŸturuluyor...")
        test_scenario_path = "tests/dry-run-test.yaml"
        
        if create_example_scenario(test_scenario_path):
            print(f"âœ… Test scenario oluÅŸturuldu: {test_scenario_path}")
        else:
            print("âŒ Test scenario oluÅŸturulamadÄ±")
            return False
        
        # 2. Scenario'yu yÃ¼kle ve validate et
        print("\nğŸ” Scenario yÃ¼kleniyor ve validate ediliyor...")
        scenario = load_scenario(test_scenario_path)
        
        if scenario:
            print(f"âœ… Scenario yÃ¼klendi: {scenario.name}")
            print(f"   ğŸ“Š Step sayÄ±sÄ±: {len(scenario.steps)}")
            print(f"   ğŸŒ Browser: {scenario.browser}")
            print(f"   ğŸ‘ï¸  Headless: {scenario.headless}")
        else:
            print("âŒ Scenario yÃ¼klenemedi")
            return False
        
        # 3. CrewManager'Ä± baÅŸlat
        print("\nğŸ¤– CrewManager baÅŸlatÄ±lÄ±yor...")
        crew_manager = CrewManager(llm_model="gpt-4o-mini", headless=True)
        print("âœ… CrewManager baÅŸlatÄ±ldÄ±")
        
        # 4. Scenario'yu Ã§alÄ±ÅŸtÄ±r (mock mode)
        print("\nâš¡ Scenario Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor (Mock Mode)...")
        print("   âš ï¸  Not: Bu bir mock execution'dÄ±r, gerÃ§ek browser aÃ§Ä±lmayacak")
        
        # Mock execution
        result = await crew_manager.run_scenario(test_scenario_path)
        
        # 5. SonuÃ§larÄ± analiz et
        print("\nğŸ“Š SonuÃ§lar analiz ediliyor...")
        
        if result.get("status") == "error":
            print(f"âŒ Test baÅŸarÄ±sÄ±z: {result.get('error', 'Bilinmeyen hata')}")
            return False
        
        # Result structure'Ä±nÄ± kontrol et
        required_keys = ["metadata", "summary", "execution", "verification"]
        missing_keys = [key for key in required_keys if key not in result]
        
        if missing_keys:
            print(f"âš ï¸  Eksik result anahtarlarÄ±: {missing_keys}")
        else:
            print("âœ… Result structure tamamlanmÄ±ÅŸ")
        
        # Summary bilgilerini gÃ¶ster
        if "summary" in result:
            summary = result["summary"]
            print(f"\nğŸ¯ Test Ã–zeti:")
            print(f"   ğŸ“ˆ Overall Status: {summary.get('overall_status', 'unknown')}")
            print(f"   ğŸ“Š Toplam Step: {summary.get('total_steps', 0)}")
            print(f"   âœ… BaÅŸarÄ±lÄ±: {summary.get('passed', 0)}")
            print(f"   âŒ BaÅŸarÄ±sÄ±z: {summary.get('failed', 0)}")
            print(f"   ğŸ“ˆ BaÅŸarÄ± OranÄ±: {summary.get('success_rate', 0):.1%}")
        
        # Execution detaylarÄ±
        if "execution" in result:
            execution = result["execution"]
            print(f"\nâš¡ Execution DetaylarÄ±:")
            print(f"   â±ï¸  Toplam SÃ¼re: {execution.get('total_duration', 0):.2f} saniye")
            print(f"   ğŸ”§ Status: {execution.get('status', 'unknown')}")
            
            if "steps" in execution:
                steps = execution["steps"]
                print(f"   ğŸ“‹ Step DetaylarÄ±:")
                for i, step in enumerate(steps[:3]):  # Ä°lk 3 step
                    status = step.get("status", "unknown")
                    action = step.get("action", "unknown")
                    duration = step.get("duration", 0)
                    print(f"      {i+1}. {action}: {status} ({duration:.2f}s)")
                
                if len(steps) > 3:
                    print(f"      ... ve {len(steps)-3} step daha")
        
        print("\nğŸ‰ Dry Run Test BaÅŸarÄ±lÄ±!")
        print("âœ… Framework tam olarak Ã§alÄ±ÅŸÄ±yor")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Dry Run Test HatasÄ±: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # Cleanup - test dosyasÄ±nÄ± sil
        try:
            Path(test_scenario_path).unlink(missing_ok=True)
            print(f"\nğŸ§¹ Test dosyasÄ± temizlendi: {test_scenario_path}")
        except:
            pass

def main():
    """Main entry point"""
    
    # Logging setup
    structlog.configure(
        processors=[
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.add_log_level,
            structlog.processors.JSONRenderer()
        ],
        logger_factory=structlog.PrintLoggerFactory(),
        wrapper_class=structlog.make_filtering_bound_logger(20),  # INFO level
        cache_logger_on_first_use=True,
    )
    
    # Run test
    success = asyncio.run(test_full_workflow())
    
    if success:
        print("\nğŸ¯ SONUÃ‡: Framework doÄŸrulanmÄ±ÅŸ ve kullanÄ±ma hazÄ±r!")
        sys.exit(0)
    else:
        print("\nğŸ’¥ SONUÃ‡: Framework'de sorunlar var!")
        sys.exit(1)

if __name__ == "__main__":
    main() 